# Отток клиентов

## Описание проекта

Из банка стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.  

## Задача проекта

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

## Описание данных

Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

## Признаки

- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата

## Целевой признак

- Exited — факт ухода клиента

## План исследования:

1. Загрузка датасета
2. Предобработка данных (проверка пропущенных значений, типов данных, явных дублей)
3. Исследовательский анализ данных (изучить основную информацию о данных, построить графики, проверить корреляцию данных)
4. Определить целевой признак и создать отдельные датасеты с целевым и прочими признаками для предсказаний для каждой выборки
5. Разделить исходные данные на 3 части: обучающую, валидационную и тестовую выборки
6. Определить, к какому виду исследования относится наше исследование: Классификация или Регрессия
7. Определить, какие модели обучения будем тестировать
8. Тест моделей на обучающей и валидационной выборках без учёта дисбаланса
9. Применить несколько способов борьбы с дисбалансом (upsample и downsample)
10. Тест моделей на обучающей и валидационной выборках c учётом дисбаланса
11. Определение лучшей модели и гиперпараметров (с лучшим показателем f1, не меньше 0.59)
12. Проверить качество лучшей модели на тестовой выборке
13. Исследовать метрику AUC-ROC

## Решение

**Для создания предсказаний были использованы 3 модели классификации:**

* Дерево решений (Tree Decision)
* Случайный лес (Random Forest)
* Логистическая регрессия 

**В рамках борьбы с дисбалансом классов было рассмотрено 2 метода:**

* upsampling
* downsampling

**Также использовались:**

* метод get_dummies для преобразования категориальных значений в числа для обучения моделей.
* метод стандартизации данных StandardScaler() для масштабирования признаков

## Результат

Лучший результат показала модель Случайного леса после upsample: 0.64 (max_depth = 12, n_estimators равному = 40).
Эту модель и гиперпараметры взяли для обучения модели на тестовой выборке. В результате обучения получили f1-меры 0.60, что превышает требование заказчика (0.59). 
  
Дополнительно проверили AUC-ROC, получили значение 0.85, что является достаточно высоким показателем. 
Это показывает достаточно высокую точность определения позитивных кейсов. Таким образом, можем считать, что цель исследования была достигнута.

## Используемые библиотеки

Pandas, Matplotlib, Seaborn, Sklearn 
